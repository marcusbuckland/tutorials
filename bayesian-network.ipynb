{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Network\n",
    "\n",
    "**Bayesian (belief) network** is a very powerful model to represent the uncertainty in the world, including the **dependencies** between different random variables (events) in the real world, and the corresponding **(conditional) probabilities**.\n",
    "\n",
    "In this tutorial, we will introduce the Bayesian network, how to build a Bayesian network, and do inference in a Bayesian network.\n",
    "\n",
    "# Table of Contents <a name=\"toc\"></a>\n",
    "\n",
    "1. [Bayesian Network Definition](#definition)\n",
    "2. [Cause, Effect, (In)dependencies](#dependency)\n",
    "3. [Factorisation](#factorisation)\n",
    "4. [Number of Free Parameters](#freepara)\n",
    "5. [Building Bayesian Network](#building)\n",
    "6. [Build Bayesian Network through `pgmpy`](#pgmpy)\n",
    "7. [Inference in Bayesian Network](#inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bayesian Network Definition <a name=\"definition\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Alarm World\n",
    "\n",
    "Let us consider the following \"*alarm world*\": you installed an **alarm** system in your house against **burglary**. However, New Zealand frequently has **earthquakes**, and the alarm system can be occasionally set off by an earthquake as well. In addition, the alarm can be set off by mistake with a very small probability. You have two neighbours, **John** and **Mary**. They might call you if they hear the alarm from your house while you are away. On the other hand, they might still call you for other issues even if they do not hear the alarm. However, they do not know each other, thus they will not communicate with each other about calling you.\n",
    "\n",
    "<img src=\"img/alarm.png\" width=300></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Variables\n",
    "\n",
    "In this \"alarm world\", there are five binary **random variables**.\n",
    "\n",
    "- $B$: Whether a **b**urglar breaks into the house or not.\n",
    "- $E$: Whether there is an **e**arthquake or not.\n",
    "- $A$: Whether the **a**larm is set off or not.\n",
    "- $J$: Whether your neighbour **J**ohn calls you or not.\n",
    "- $M$: Whether your neighbour **M**ary calls you or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (In)dependencies\n",
    "\n",
    "From domain knowledge, we have the following **(in)dependencies** between the random variables.\n",
    "\n",
    "- The alarm can be set off by a burglar.\n",
    "- The alarm can be set off by an earthquake.\n",
    "- Whether a burglar breaks into the house is independent from whether there is an earthquake.\n",
    "- John might call you if they hear the alarm.\n",
    "- Mary might call you if they hear the alarm.\n",
    "- Since John and Mary do not communicate, **given the alarm condition**, whether John calls is independent from whether Mary calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directed Acyclic Graph\n",
    "\n",
    "Based on the above domain knowledge, we can represent the random variables in the alarm world and their (in)dependencies by the following **Directed Acyclic Graph (DAG)**. \n",
    "\n",
    "<img src=\"img/alarm-dag.png\" width=150></img>\n",
    "\n",
    "We can see that each **node** represents a random variable, and each **directed edge** represents a causal dependency between the variables. For example, the directed edge $(B, A)$ means that the burglary variable is a cause of the alarm variable, and the alarm variable is an effect of the burglary variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Conditional) Probabilities\n",
    "\n",
    "The causal dependencies are qualitative. For quantitative reasoning, we need the (conditional) probabilities for each random variable in the DAG.\n",
    "\n",
    "Again, from domain knowledge, we have the following probabilities.\n",
    "\n",
    "- A burglar breaks into the house with probability of 0.1%.\n",
    "- The probability of an earthquake is 0.2%.\n",
    "- If there were both a burglar and an earthquake, the alarm is set off with probability of 95%.\n",
    "- If there was a burglar but no earthquake, the alarm is set off with probability of 94%.\n",
    "- If there was no burglar and an earthquake, the alarm is set off with probability of 29%.\n",
    "- If there was no burglar and no earthquake, the alarm is set off by mistake with probability of 0.1%.\n",
    "- If the alarm is set off, John will hear it and call you with probability of 90%.\n",
    "- If the alarm is not set off, John will call you for other issues with probability of 5%.\n",
    "- If the alarm is set off, Mary will hear it and call you with probability of 70%.\n",
    "- If the alarm is not set off, Mary will call you for other issues with probability of 1%.\n",
    "\n",
    "Based on the above probabilities, we can have the following **Bayesian network** for the alarm world.\n",
    "\n",
    "<img src=\"img/alarm-bn.png\" width=500></img>\n",
    "\n",
    "From the above example, we can see that to define a Bayesian network, we need to define\n",
    "\n",
    "1. A **Directed Acyclic Graph (DAG)**, where each **node** represents a **random variable** in the world, and each **directed edge** represents a **causal dependency** between two random variables\n",
    "2. A **Conditional Probability Table (CPT)** for each node $X$ in the graph. The conditional probabilities are $P(X\\ |\\ parents(X))$, where $parents(X)$ are the parents (incoming neighbours) of $X$ in the graph. They are direct causes of $X$.\n",
    "\n",
    "---------\n",
    "\n",
    "*[Back to Table of Content](#toc)*\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cause, Effect, (In)dependencies <a name=\"dependency\"></a>\n",
    "\n",
    "An important task in a Bayesian network is to identify the **(in)dependencies** between any pair of random variables in the network. In general, there are four types of common (in)dependencies between variables.\n",
    "\n",
    "<img src=\"img/cause-effect.png\" width=550></img>\n",
    "\n",
    "- **Direct Cause**: $A$ is a direct cause of $B$, if $A$ is an incoming neighbour of $B$. Obviously we have\n",
    "    - $A$ **and $B$ are <span style=\"color: red;\">dependent</span>**.\n",
    "- **Indirect Cause**: $A$ is an indirected cause of $C$, if there is a directed path from $A$ to $C$. In the above 3-node example, the directed path is $A \\rightarrow B \\rightarrow C$. We have \n",
    "    - $A$ **and $C$ are conditionally <span style=\"color: blue;\">independent</span> given $B$**. This is obvious, since if the direct cause is given, then the indirect cause is not needed.\n",
    "- **Common Cause**: $B$ and $C$ have the common cause $A$, and they are not direct cause of each other. We have\n",
    "    - $B$ **and $C$ are conditionally <span style=\"color: blue;\">independent</span> given $A$**.\n",
    "    - $B$ **and $C$ are <span style=\"color: red;\">dependent</span> with each other if $A$ is not given**. This is because if $A$ is not given, then the probability of $A$ is dependent on $B$ (or $C$), which in turn changes the probability of $C$ (or $B$).\n",
    "- **Common Effect**: $A$ and $B$ have the common effect $C$, and they are not direct cause of each other. We have\n",
    "    - $A$ **and $B$ are <span style=\"color: blue;\">independent</span>** ($C$ is not given).\n",
    "    - $A$ **and $B$ are conditionally <span style=\"color: red;\">dependent</span> given $C$**. This is also called \"explaining away\". Since both $A$ and $B$ are the causes of $C$, if $C$ is given, either $A$ or $B$ can be the cause. Thus, one cause can \"explain away\" the other. For example, in the alarm network, both burglary and earthquake are the causes of the alarm. Given that the alarm is set off, if we know that there is a burglary, then there is no need to require earthquake to set off the alarm, and the conditional probability of earthquake is reduced. On the other hand, if we know that there is no burglary, then earthquake becomes the main cause of the alarm, and its conditional probability must be very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independencies in the Alarm Network\n",
    "\n",
    "From the above alarm network, we can find the following independencies:\n",
    "\n",
    "- $B$ and $E$ are independent\n",
    "- $B$ and $J$ are conditionally independent given $A$ (indirect cause)\n",
    "- $B$ and $M$ are conditionally independent given $A$ (indirect cause)\n",
    "- $E$ and $J$ are conditionally independent given $A$ (indirect cause)\n",
    "- $E$ and $M$ are conditionally independent given $A$ (indirect cause)\n",
    "- $J$ and $M$ are conditionally independent given $A$ (common cause)\n",
    "\n",
    "> **NOTE**: $B$ and $E$ will become <span style=\"color: red;\">dependent</span> if $A$ is given, due to common effect (explaining away).\n",
    "\n",
    "---------\n",
    "\n",
    "*[Back to Table of Content](#toc)*\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Factorisation <a name=\"factorisation\"></a>\n",
    "\n",
    "The independencies in a Bayesian network can be summarised as follows.\n",
    "\n",
    "> **THEOREM**: In a Bayesian network, a node is conditionally independent from **all the nodes except its direct effects**, if the **direct causes are all given**, and **no direct effect is given**.\n",
    "\n",
    "**Proof**\n",
    "\n",
    "1. Given all the direct causes, a node is conditionally independent from all its indirect causes, as well as any other cause/effect node extended from its indirect causes.\n",
    "2. Given all the direct causes, a node is conditionally independent from all the direct effects of its direct causes (common cause), as well as any other cause/effect node extended from them.\n",
    "3. If no direct effect is given, then a node is conditionally independent from the direct cause of its direct effect (common effect), as well as any other cause/effect node extended from them.\n",
    "4. There is no other node than the above categories.\n",
    "\n",
    "<div style=\"text-align: right\"> $\\blacksquare$ </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a Bayesian network with the nodes $\\{X_1, \\dots, X_n\\}$. We can have the following theorem.\n",
    "\n",
    "> **THEOREM**: If the order of $\\{X_1, \\dots, X_n\\}$ is consistent with the nodes in the directed acyclic graph, i.e., for each node $X_i$, no direct effect of $X_i$ is before it, then each node $X_i$ is conditionally independent from all the nodes in $\\{X_1, \\dots, X_{i-1}\\}$ except its direct cause, if all its direct causes are given.\n",
    "\n",
    "**Proof**\n",
    "\n",
    "First, from the order of the nodes in the network, we have\n",
    "\n",
    "- **All the directed causes of $X_i$ are in $\\{X_1, \\dots, X_{i-1}\\}$**. Otherwise, if a direct cause of $X_i$ is outside $\\{X_1, \\dots, X_{i-1}\\}$, there must be a directed path from outside $\\{X_1, \\dots, X_{i-1}\\}$ to $X_i$, which contradicts the order of the nodes.\n",
    "\n",
    "Second, the node order already tells that no direct effect of $X_i$ is in $\\{X_1, \\dots, X_{i-1}\\}$. Therefore, from Theorem 1, we have that each node $X_i$ is conditionally independent from all the nodes in $\\{X_1, \\dots, X_{i-1}\\}$ except its direct cause, if all its direct causes are given.\n",
    "\n",
    "<div style=\"text-align: right\"> $\\blacksquare$ </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above theorem can be written as\n",
    "\n",
    "$$\n",
    "P(X_i\\ |\\ X_1, \\dots, X_{i-1}) = P(X_i\\ |\\ parents(X_i)),\n",
    "$$\n",
    "\n",
    "where $parents(X_i)$ are the parents (direct causes) of $X_i$.\n",
    "\n",
    "For example, we can have some equations for the alarm network as follows:\n",
    "\n",
    "$$\n",
    "P(J\\ |\\ A, B, E) = P(J\\ |\\ A),\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(M\\ |\\ A, B, J) = P(M\\ |\\ A),\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(J\\ |\\ A, B, E, M) = P(J\\ |\\ A),\n",
    "$$\n",
    "\n",
    "On the other hand, from the chain (product) rule, we have \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& P(X_1, \\dots, X_n) \\\\\n",
    "& = P(X_1) * P(X_2\\ |\\ X_1) * \\dots * P(X_n\\ |\\ X_1, \\dots, X_{n-1}).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Therefore, the Bayesian network can be written as the following **factorisation** of joint probability distribution.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& P(X_1, \\dots, X_n) \\\\\n",
    "& = P(X_1\\ |\\ parents(X_1)) \\dots * P(X_n\\ |\\ parents(X_n)).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "For example, in the above alarm network, the factorisation is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& P(B, E, A, J, M) \\\\\n",
    "& = P(B) * P(E) * P(A\\ |\\ B, E) * P(J\\ |\\ A) * P(M\\ |\\ A).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "> **NOTE**: The factorisation of the joint probability distribution is equivelant to the representation of previous graph + probability tables.\n",
    "\n",
    "---------\n",
    "\n",
    "*[Back to Table of Content](#toc)*\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Number of Free Parameters <a name=\"freepara\"></a>\n",
    "\n",
    "To store a Bayesian network, we need to store the graph and the probability tables of each node. Obviously, the probability tables dominate the graph in the memory requirement, thus we focus on the memory requirement of the probability tables.\n",
    "\n",
    "For the sake of convenience, we only consider **discrete** variables in the network, and the continuous variables will be discretised. Then, for each variable $X$ in the network, we have the following notations.\n",
    "\n",
    "- $\\Omega(X)$: the domain (set of possible values) of $X$\n",
    "- $|\\Omega(X)|$: the number of possible values of $X$\n",
    "- $parents(X)$: the parents (direct causes) of $X$ in the network\n",
    "\n",
    "For each variable $X$, the probability table stores the probabilities for $P(X\\ |\\ parents(X))$ for different $X$ values and $parent(X)$ values. Let's consider the following situations:\n",
    "\n",
    "1. $X$ does not have any parent. In this case, the table stores $P(X)$. There are $|\\Omega(X)|$ probabilities, each for a possible value of $X$. However, due to the [normalisation rule](https://homepages.ecs.vuw.ac.nz/~yimei/tutorials/reasoning-under-uncertainty-basics.html#probrules), all the probabilities add up to 1. Thus, we need to store only $|\\Omega(X)|-1$ probabilities, and the last probability can be calculated by ($1-$the sum of the stored probabilities). Therefore, the probability table contains $|\\Omega(X)|-1$ rows/probabilities.\n",
    "2. $X$ has one parent $Y$. In this case, for each condition $y \\in \\Omega(Y)$, we need to store the conditional probabilities $P(X\\ |\\ Y = y)$. Again, we need to store $|\\Omega(X)|-1$ conditional probabilities for $P(X\\ |\\ Y = y)$, and can calculate the last conditional probability by the normalisation rule. Therefore, the probability table contains $(|\\Omega(X)|-1)*|\\Omega(Y)|$ rows/probabilities.\n",
    "3. $X$ has multiple parents $Y_1, \\dots, Y_m$. In this case, there are $|\\Omega(Y_1)|*\\dots * |\\Omega(Y_m)|$ possible conditions $[Y_1 = y_1, \\dots, Y_m = y_m]$. For each condition, we need to store $|\\Omega(X)|-1$ conditional probabilities for $P(X\\ |\\ Y_1 = y_1, \\dots, Y_m = y_m)$. Therefore, the probability table contains $(|\\Omega(X)|-1)*|\\Omega(Y_1)|*\\dots * |\\Omega(Y_m)|$ rows/probabilities.\n",
    "\n",
    "As shown in the above alarm network, all the variables are binary, i.e. $|\\Omega(X)| = 2$. Therefore, $B$ and $E$ have only 1 row in their probability tables, since they have no parent. $A$ has $1 \\times 2 \\times 2 = 4$ rows in its probability tables, since it has two binary parents $B$ and $E$, leading to four possible conditions.\n",
    "\n",
    "> **DEFINITION**: The **number of free parameters** of a Bayesian network is the number of probabilities we need to estimate and store (can NOT be derived/calculated) in the probability tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a Bayesian network with the factorisation\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& P(X_1, \\dots, X_n) \\\\\n",
    "& = P(X_1\\ |\\ parents(X_1)) \\dots * P(X_n\\ |\\ parents(X_n)),\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "the number of free parameters is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(X_1, \\dots, X_n) & = (|\\Omega(X_1)|-1)*\\prod_{Y \\in parents(X_1)}|\\Omega(Y)| \\\\\n",
    "& + (|\\Omega(X_2)|-1)*\\prod_{Y \\in parents(X_2)}|\\Omega(Y)| \\\\\n",
    "& + \\dots \\\\\n",
    "& + (|\\Omega(X_n)|-1)*\\prod_{Y \\in parents(X_n)}|\\Omega(Y)|. \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the number of free parameters of the following simple networks, assuming that all the variables are binary.\n",
    "\n",
    "- **Direct cause**: $P(A)$ has 1 free parameter, $P(B\\ |\\ A)$ has 2 free parameters. The network has $1+2 = 3$ free parameters.\n",
    "- **Indirect cause**: $P(A)$ has 1 free parameter, $P(B\\ |\\ A)$ and $P(C\\ |\\ B)$ have 2 free parameters. The network has $1+2+2 = 5$ free parameters.\n",
    "- **Common cause**: $P(A)$ has 1 free parameter, $P(B\\ |\\ A)$ and $P(C\\ |\\ A)$ have 2 free parameters. The network has $1+2+2 = 5$ free parameters.\n",
    "- **Common effect**: $P(A)$ and $P(B)$ have 1 free parameter, $P(C\\ |\\ A, B)$ has $2\\times 2 = 4$ free parameters. The network has $1+1+4 = 6$ free parameters.\n",
    "\n",
    "<img src=\"img/cause-effect.png\" width=550></img>\n",
    "\n",
    "> **NOTE**: We can see that the common effect dependency causes the most free parameters required for the network. Therefore, when building a Bayesian network, we should try to reduce the number of such dependencies to reduce the number of free parameters of the network.\n",
    "\n",
    "---------\n",
    "\n",
    "*[Back to Table of Content](#toc)*\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building Bayesian Network <a name=\"building\"></a>\n",
    "\n",
    "Building a Bayesian network mainly consists of the following three steps:\n",
    "\n",
    "1. Identify a set of **random variables** that describe the world of reasoning.\n",
    "2. Build the **directed acyclic graph**, i.e., the **directed links** between the random variables.\n",
    "3. Build the **conditional probability table** for each variable, by estimating the necessary probabilities.\n",
    "\n",
    "Here, we introduce the Pearl's network construction algorithm, which is a way to build the network based on **node ordering**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "# Step 1: identify variables\n",
    "Identify the random variables that describe the world of reasoning\n",
    "# Step 2: build the graph, add the links\n",
    "Sort the random variables by some order\n",
    "Set bn = []\n",
    "for var in sorted_vars:\n",
    "    Find the minimum subset of variables in bn so that P(var | bn) = P(var | subset)\n",
    "    \n",
    "    Add var into bn\n",
    "    for bn_var in subset:\n",
    "        Add a direct link [bn_var, var]\n",
    "    # Step 3: estimate the conditional probability table\n",
    "    Estimate the conditional probabilities P(var | subset)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this algorithm, the **node ordering** is critical to determine the number of links between the nodes, and thus the size of the conditional probability tables. \n",
    "\n",
    "We show how the links are added in to the network under different node orders, using the alarm network as an example.\n",
    "\n",
    "----------\n",
    "\n",
    "#### Order 1: $B \\rightarrow E \\rightarrow A \\rightarrow J \\rightarrow M$\n",
    "\n",
    "- **Step 1**: The node $B$ is added into the network. No edge is added, since there is only one node in the network.\n",
    "- **Step 2**: The node $E$ is added into the network. No edge from $B$ to $E$ is added, since $B$ and $E$ are independent.\n",
    "- **Step 3**: The node $A$ is added into the network. Two edges $[B, A]$ and $[E, A]$ are added, since $B$ and $E$ are both direct causes of $A$.\n",
    "- **Step 4**: The node $J$ is added into the network. The minimum subset $A \\subseteq \\{B, E, A\\}$ in the network is found to be the parent of $J$, since $J$ is conditionally independent from $B$ and $E$ given $A$, i.e., $P(J\\ |\\ B, E, A) = P(J\\ |\\ A)$. An edge $[A, J]$ is added into the network.\n",
    "- **Step 5**: The node $M$ is added into the network. The minimum subset $A \\subseteq \\{B, E, A, J\\}$ in the network is found to be the parent of $M$, since $M$ is conditionally independent from $B$, $E$ and $J$ given $A$, i.e., $P(M\\ |\\ B, E, A, J) = P(M\\ |\\ A)$. An edge $[A, M]$ is added into the network.\n",
    "\n",
    "The built network is shows as follows. The number of free parameters in this network is $1 + 1 + 4 + 2 + 2 = 10$.\n",
    "\n",
    "<img src=\"img/alarm-dag.png\" width=150></img>\n",
    "\n",
    "----------\n",
    "\n",
    "#### Order 2: $J \\rightarrow M \\rightarrow A \\rightarrow B \\rightarrow E$\n",
    "\n",
    "- **Step 1**: The node $J$ is added into the network. No edge is added, since there is only one node in the network.\n",
    "- **Step 2**: The node $M$ is added into the network. $M$ and $J$ are dependent (note that the common cause $A$ is not given at this step), i.e., $P(M\\ |\\ J) \\neq P(M)$. Therefore, an edge $[J, M]$ is added into the network.\n",
    "- **Step 3**: The node $A$ is added into the network. Two edges $[J, A]$ and $[M, A]$ are added, since $J$ and $M$ are both dependent on $A$.\n",
    "- **Step 4**: The node $B$ is added into the network. The minimum subset $A \\subseteq \\{J, M, A\\}$ in the network is found to be the parent of $B$, since $B$ is conditionally independent from $J$ and $M$ given $A$, i.e., $P(B\\ |\\ J, M, A) = P(B\\ |\\ A)$. An edge $[A, B]$ is added into the network.\n",
    "- **Step 5**: The node $E$ is added into the network. The minimum subset $\\{A, B\\} \\subseteq \\{J, M, A, B\\}$ in the network is found to be the parent of $E$, since $E$ is conditionally independent from $J$ and $M$ given $A$ and $E$, i.e., $P(M\\ |\\ J, M, A, B) = P(M\\ |\\ A, B)$ (note that $B$ and $E$ have the common effect $A$, thus when $A$ is given, $B$ and $E$ are conditionally dependent). Two edges $[A, E]$ and $[B, E]$ are added into the network.\n",
    "\n",
    "The built network is shows as follows. The number of free parameters in this network is $1 + 2 + 4 + 2 + 4 = 13$.\n",
    "\n",
    "<img src=\"img/alarm-dag2.png\" width=150></img>\n",
    "\n",
    "----------\n",
    "\n",
    "#### Order 3: $J \\rightarrow M \\rightarrow B \\rightarrow E \\rightarrow A$\n",
    "\n",
    "- **Step 1**: The node $J$ is added into the network. No edge is added, since there is only one node in the network.\n",
    "- **Step 2**: The node $M$ is added into the network. $M$ and $J$ are dependent (note that the common cause $A$ is not given at this step), i.e., $P(M\\ |\\ J) \\neq P(M)$. Therefore, an edge $[J, M]$ is added into the network.\n",
    "- **Step 3**: The node $B$ is added into the network. Two edges $[J, B]$ and $[M, B]$ are added, since $J$ and $M$ are both dependent on $B$ (through $A$, which has not been added yet).\n",
    "- **Step 4**: The node $E$ is added into the network. There is no conditional independence found among $\\{J, M, B, E\\}$ without giving $A$. Therefore, three edges $[J, E]$, $[M, E]$, $[B, E]$ are added into the network.\n",
    "- **Step 5**: The node $A$ is added into the network. First, two edges Two edges $[J, A]$ and $[M, A]$ are added, since $J$ and $M$ are both dependent on $A$. Then, another two edges $[B, A]$ and $[E, A]$ are also added, since $B$ and $E$ are both direct causes of $A$.\n",
    "\n",
    "The built network is shows as follows. The number of free parameters in this network is $1 + 2 + 4 + 8 + 16 = 31$.\n",
    "\n",
    "<img src=\"img/alarm-dag3.png\" width=200></img>\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that different node orders can lead to greatly different graphs and numbers of free parameters. Therefore, we should find the **optimal node order** that leads to the most **compact** network (with the fewest free parameters).\n",
    "\n",
    "> **QUESTION**: How to find the optimal node order that leads to the most compact Bayesian network?\n",
    "\n",
    "The node order is mainly determined based on our **domain knowledge** about **cause and effect**. At first, we add the nodes with no cause (i.e., the root causes) into the ordered list. Then, at each step, we find the remaining nodes whose direct causes are all in the current ordered list (i.e., all their direct causes are given) and append them into the end of the ordered list. This way, we only need to add direct links from their direct causes to them.\n",
    "\n",
    "The pseucode of the node ordering is shown as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "def node_ordering(all_nodes):\n",
    "    Set ordered_nodes = [], remaining_nodes = all_nodes\n",
    "    while remaining_nodes is not empty:\n",
    "        Select the nodes whose direct causes are all in ordered_nodes\n",
    "        Append the selected nodes into ordered_nodes\n",
    "        Remove the selected nodes from remaining_nodes\n",
    "    return ordered_nodes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the alarm network, first we add two nodes $\\{B, E\\}$ into the ordered list, since they are the root causes, and have no direct cause. Then, we add $A$ into the ordered list, since it has two direct causes $B$ and $E$, both are already in the ordered list. Finally, we add $J$ and $M$ into the list, since their direct cause $A$ is already in the ordered list.\n",
    "\n",
    "---------\n",
    "\n",
    "*[Back to Table of Content](#toc)*\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build Bayesian Network through `pgmpy` <a name=\"pgmpy\"></a>\n",
    "\n",
    "Here, we show how to build the alarm network through the Python [pgmpy](https://pgmpy.org) library. The alarm network is displayed again below.\n",
    "\n",
    "<img src=\"img/alarm-bn.png\" width=500></img>\n",
    "\n",
    "First, we install the library using `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fYQb_1imtaRM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pgmpy in /Users/yimei/miniforge3/lib/python3.9/site-packages (0.1.17)\n",
      "Requirement already satisfied: statsmodels in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pgmpy) (0.13.2)\n",
      "Requirement already satisfied: joblib in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pgmpy) (1.1.0)\n",
      "Requirement already satisfied: scipy in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pgmpy) (1.8.0)\n",
      "Requirement already satisfied: networkx in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pgmpy) (2.7.1)\n",
      "Requirement already satisfied: pandas in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pgmpy) (1.3.2)\n",
      "Requirement already satisfied: numpy in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pgmpy) (1.21.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pgmpy) (1.0.2)\n",
      "Requirement already satisfied: pyparsing in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pgmpy) (3.0.6)\n",
      "Requirement already satisfied: tqdm in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pgmpy) (4.62.1)\n",
      "Requirement already satisfied: torch in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pgmpy) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pandas->pgmpy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/yimei/miniforge3/lib/python3.9/site-packages (from pandas->pgmpy) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yimei/miniforge3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->pgmpy) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/yimei/miniforge3/lib/python3.9/site-packages (from scikit-learn->pgmpy) (3.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/yimei/miniforge3/lib/python3.9/site-packages (from statsmodels->pgmpy) (21.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Users/yimei/miniforge3/lib/python3.9/site-packages (from statsmodels->pgmpy) (0.5.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/yimei/miniforge3/lib/python3.9/site-packages (from torch->pgmpy) (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pgmpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we import the necessary modules for the Bayesian network as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1645147874773,
     "user": {
      "displayName": "Yi Mei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjbsloGGj8mKvkgwfMTyhu9iqFZUz599lVh7y-zA=s64",
      "userId": "14923329265121969261"
     },
     "user_tz": -780
    },
    "id": "qFLJyY014YDo"
   },
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we build the alarm Bayesian network as follows.\n",
    "\n",
    "1. We define the network structure by specifying the four links.\n",
    "2. We define (estimate) the discrete conditional probability tables, represented as the `TabularCPD` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1645148217327,
     "user": {
      "displayName": "Yi Mei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjbsloGGj8mKvkgwfMTyhu9iqFZUz599lVh7y-zA=s64",
      "userId": "14923329265121969261"
     },
     "user_tz": -780
    },
    "id": "4JmRhyQ4PSHm"
   },
   "outputs": [],
   "source": [
    "# Define the network structure\n",
    "alarm_model = BayesianNetwork(\n",
    "    [\n",
    "        (\"Burglary\", \"Alarm\"),\n",
    "        (\"Earthquake\", \"Alarm\"),\n",
    "        (\"Alarm\", \"JohnCall\"),\n",
    "        (\"Alarm\", \"MaryCall\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the probability tables by TabularCPD\n",
    "cpd_burglary = TabularCPD(\n",
    "    variable=\"Burglary\", variable_card=2, values=[[0.999], [0.001]]\n",
    ")\n",
    "\n",
    "cpd_earthquake = TabularCPD(\n",
    "    variable=\"Earthquake\", variable_card=2, values=[[0.998], [0.002]]\n",
    ")\n",
    "\n",
    "cpd_alarm = TabularCPD(\n",
    "    variable=\"Alarm\",\n",
    "    variable_card=2,\n",
    "    values=[[0.999, 0.71, 0.06, 0.05], [0.001, 0.29, 0.94, 0.95]],\n",
    "    evidence=[\"Burglary\", \"Earthquake\"],\n",
    "    evidence_card=[2, 2],\n",
    ")\n",
    "\n",
    "cpd_johncall = TabularCPD(\n",
    "    variable=\"JohnCall\",\n",
    "    variable_card=2,\n",
    "    values=[[0.95, 0.1], [0.05, 0.9]],\n",
    "    evidence=[\"Alarm\"],\n",
    "    evidence_card=[2],\n",
    ")\n",
    "\n",
    "cpd_marycall = TabularCPD(\n",
    "    variable=\"MaryCall\",\n",
    "    variable_card=2,\n",
    "    values=[[0.99, 0.3], [0.01, 0.7]],\n",
    "    evidence=[\"Alarm\"],\n",
    "    evidence_card=[2],\n",
    ")\n",
    "\n",
    "# Associating the probability tables with the model structure\n",
    "alarm_model.add_cpds(\n",
    "    cpd_burglary, cpd_earthquake, cpd_alarm, cpd_johncall, cpd_marycall\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the nodes of the alarm network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('Burglary', 'Alarm', 'Earthquake', 'JohnCall', 'MaryCall'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing nodes of the model\n",
    "alarm_model.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the edges of the alarm network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([('Burglary', 'Alarm'), ('Alarm', 'JohnCall'), ('Alarm', 'MaryCall'), ('Earthquake', 'Alarm')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing edges of the model\n",
    "alarm_model.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show the probability tables using the `print()` method. \n",
    "\n",
    "> **NOTE**: the `pgmpy` library stores ALL the probabilities (including the last probability). This requires a bit more memory, but can save time for calculating the last probability by normalisation rule.\n",
    "\n",
    "Let's print the probability tables for **Alarm** and **MaryCalls**. For each variable, the value (0) stands for `False`, while the value (1) is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+---------------+---------------+---------------+\n",
      "| Burglary   | Burglary(0)   | Burglary(0)   | Burglary(1)   | Burglary(1)   |\n",
      "+------------+---------------+---------------+---------------+---------------+\n",
      "| Earthquake | Earthquake(0) | Earthquake(1) | Earthquake(0) | Earthquake(1) |\n",
      "+------------+---------------+---------------+---------------+---------------+\n",
      "| Alarm(0)   | 0.999         | 0.71          | 0.06          | 0.05          |\n",
      "+------------+---------------+---------------+---------------+---------------+\n",
      "| Alarm(1)   | 0.001         | 0.29          | 0.94          | 0.95          |\n",
      "+------------+---------------+---------------+---------------+---------------+\n",
      "+-------------+----------+----------+\n",
      "| Alarm       | Alarm(0) | Alarm(1) |\n",
      "+-------------+----------+----------+\n",
      "| MaryCall(0) | 0.99     | 0.3      |\n",
      "+-------------+----------+----------+\n",
      "| MaryCall(1) | 0.01     | 0.7      |\n",
      "+-------------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Print the probability table of the Alarm node\n",
    "print(cpd_alarm)\n",
    "\n",
    "# Print the probability table of the MaryCalls node\n",
    "print(cpd_marycall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find all the **(conditional) independencies** between the nodes in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(JohnCall ⟂ Earthquake, MaryCall, Burglary | Alarm)\n",
       "(JohnCall ⟂ MaryCall, Burglary | Earthquake, Alarm)\n",
       "(JohnCall ⟂ Earthquake, Burglary | MaryCall, Alarm)\n",
       "(JohnCall ⟂ Earthquake, MaryCall | Alarm, Burglary)\n",
       "(JohnCall ⟂ Burglary | Earthquake, MaryCall, Alarm)\n",
       "(JohnCall ⟂ MaryCall | Earthquake, Alarm, Burglary)\n",
       "(JohnCall ⟂ Earthquake | MaryCall, Alarm, Burglary)\n",
       "(MaryCall ⟂ JohnCall, Earthquake, Burglary | Alarm)\n",
       "(MaryCall ⟂ Earthquake, Burglary | JohnCall, Alarm)\n",
       "(MaryCall ⟂ JohnCall, Burglary | Earthquake, Alarm)\n",
       "(MaryCall ⟂ JohnCall, Earthquake | Alarm, Burglary)\n",
       "(MaryCall ⟂ Burglary | JohnCall, Earthquake, Alarm)\n",
       "(MaryCall ⟂ Earthquake | JohnCall, Alarm, Burglary)\n",
       "(MaryCall ⟂ JohnCall | Earthquake, Alarm, Burglary)\n",
       "(Burglary ⟂ Earthquake)\n",
       "(Burglary ⟂ JohnCall, MaryCall | Alarm)\n",
       "(Burglary ⟂ MaryCall | JohnCall, Alarm)\n",
       "(Burglary ⟂ JohnCall, MaryCall | Earthquake, Alarm)\n",
       "(Burglary ⟂ JohnCall | MaryCall, Alarm)\n",
       "(Burglary ⟂ MaryCall | JohnCall, Earthquake, Alarm)\n",
       "(Burglary ⟂ JohnCall | Earthquake, MaryCall, Alarm)\n",
       "(Earthquake ⟂ Burglary)\n",
       "(Earthquake ⟂ JohnCall, MaryCall | Alarm)\n",
       "(Earthquake ⟂ MaryCall | JohnCall, Alarm)\n",
       "(Earthquake ⟂ JohnCall | MaryCall, Alarm)\n",
       "(Earthquake ⟂ JohnCall, MaryCall | Alarm, Burglary)\n",
       "(Earthquake ⟂ MaryCall | JohnCall, Alarm, Burglary)\n",
       "(Earthquake ⟂ JohnCall | MaryCall, Alarm, Burglary)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarm_model.get_independencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find the **local (conditional) independencies of a specific node** in the network as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(JohnCall ⟂ Earthquake, MaryCall, Burglary | Alarm)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking independcies of a node\n",
    "alarm_model.local_independencies(\"JohnCall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "*[Back to Table of Content](#toc)*\n",
    "\n",
    "----------\n",
    "\n",
    "## 7. Inference in Bayesian Network <a name=\"inference\"></a>\n",
    "\n",
    "In the alarm network, we might have the following questions:\n",
    "\n",
    "- If there was an earthquake, how likely Mary will call you?\n",
    "- If both John and Mary called you, how likely there was a burglary?\n",
    "- If Mary called you, how likely John will call you as well?\n",
    "\n",
    "Answering such questions is the **inference** in Bayesian network. Formally, the inference in Bayesian network is defined as follows.\n",
    "\n",
    "> **DEFINITION**: Given a set of **query** nodes $[X_1, \\dots, X_n]$, and a set of **evidence** nodes with their **observed values** $[Y_1 = y_1, \\dots, Y_m = y_m]$, the **inference** is to calculate the conditional probabilities $P(X_1, \\dots, X_n\\ |\\ Y_1 = y_1, \\dots, Y_m = y_m)$.\n",
    "\n",
    "The inference in Bayesian network is very **flexible**, and any node in the network can be a query node or an evidence node. Depending on different query and evidence nodes, some often encountered inference/reasoning scenarios are:\n",
    "\n",
    "- **Causal reasoning**: the evidence nodes are the causes of the query nodes. This is forward reasoning.\n",
    "- **Diagnostic reasoning**: the evidence nodes are the effects of the query nodes. This is backward reasoning.\n",
    "- **Inter-causal reasoning**: the evidence and query nodes are effects of some *hidden* common causes.\n",
    "\n",
    "There are two main types of inference algorithms:\n",
    "\n",
    "1. **Exact Algorithm (Inference by Enumeration)**: This can guarantee the accuracy of the calculated conditional probabilities. However, For large and complex Bayesian networks, the exact algorithms become computationally infeasible, in which case the approximate algorithms must be used. \n",
    "2. **Approximate Algorithm**: This can be much faster than the exact algorithms, although the estimated conditoinal probabilities are not 100% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.A. Exact Algorithm (Inference by Enumeration) <a name=\"exact\"></a>\n",
    "\n",
    "Let's consider the following inference scenario in the alarm network.\n",
    "\n",
    "> **QUESTION**: What is the conditional probability of burglary, given that John calls you? That is, what is $P(B\\ |\\ J = t)$?\n",
    "\n",
    "This conditional probability cannot be calculated directly from $B$ and $J$ alone. We need to consider other variables ($E$, $A$ and $M$) in the network as well.\n",
    "\n",
    "However, not all the other variables are necessary. **Which other nodes in the network are necessary for the inference**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Markov Blanket and Boundary\n",
    "\n",
    "To find the necessary other nodes for inference, we first introduce the following concepts:\n",
    "\n",
    "> **DEFINITION**: A **Markov blanket** of a random varaible $X$ in a set of variables $\\mathcal{H} = \\{H_1, \\dots, H_k\\}$ is any **subset** $\\mathcal{B} \\subseteq \\mathcal{H}$, so that $X$ is conditionally independent from all the other variables in $\\mathcal{H} \\setminus \\mathcal{B}$ if $\\mathcal{B}$ is given. That is, $P(X\\ |\\ \\mathcal{H}) = P(X_i\\ |\\ \\mathcal{B})$.\n",
    "\n",
    "> **DEFINITION**: A **Markov boundary** $\\mathcal{B}^*$ of a random varaible $X$ in a set of variables $\\mathcal{H} = \\{H_1, \\dots, H_k\\}$ is the **minimal Markov blanket**. In other words, (1) $\\mathcal{B}^*$ is a Markov blanket of $X$, and (2) any subset of $\\mathcal{B}^*$ is NOT a Markov blanket of $X$.\n",
    "\n",
    "Obviously, for any node $X$ in the network, its **Markov boundary** is the minimal subset of nodes necessary for the inference, and all the other nodes in the network are useless.\n",
    "\n",
    "For Bayesian network, we have the following important [theorem](https://en.wikipedia.org/wiki/Markov_blanket).\n",
    "\n",
    "> **THEOREM**: The **Markov boundary** of a node $X$ in a Bayesian network consists of (1) $X$'s direct causes; (2) $X$'s direct effects; and (3) other direct causes of $X$'s direct effects.\n",
    "\n",
    "In the inference of $P(B\\ |\\ J = t)$, the Markov boundary of the query node $B$ in the network contains $A$ (direct effect) and $E$ (the other cause of its direct effect $A$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Hidden Nodes\n",
    "\n",
    "From the theorem, we know that to infer a node $X$, we need the nodes in its Markov boundary. Thus, we can find all the necessary hidden nodes to infer $P(X_1, \\dots, X_n\\ |\\ Y_1 = y_1, \\dots, Y_m = y_m)$ as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "def find_hidden_nodes(query_nodes, evidence_nodes):\n",
    "    # Initially, there is no hidden node, and the query nodes are random nodes for inference\n",
    "    Set hidden_nodes = [], rand_nodes = query_nodes\n",
    "    \n",
    "    while rand_nodes is not empty:\n",
    "        # At each step, select a random variable in the inference and explore its Markov boundary\n",
    "        Select and remove a node from rand_nodes\n",
    "        for var in markov_boundary(node):\n",
    "            # If var is already an evidence node, then skip; \n",
    "            # Otherwise, var is a hidden node, and its Markov boundary needs to be explored\n",
    "            if var in evidence_nodes:\n",
    "                continue\n",
    "            \n",
    "            Add var into hidden_nodes \n",
    "            Add var into rand_nodes\n",
    "            \n",
    "    return hidden_nodes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the inference of $P(B\\ |\\ J = t)$, \n",
    "\n",
    "- In iteration 1, we add $E$ and $A$ into `hidden_nodes`;\n",
    "- In iteration 2, we add $M$ into `hidden_nodes`, as it is in the Markov boundary of $A$.\n",
    "\n",
    "In the end, all the other nodes $E$, $A$, and $M$ in the network are hidden nodes for inferring $P(B\\ |\\ J = t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability Calculation by Factorisation\n",
    "\n",
    "After finding all the hidden nodes $\\{E, A, M\\}$, we can calculate $P(B\\ |\\ J = t)$ by as follows.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& P(B\\ |\\ J = t) & \\\\\n",
    "& = \\frac{P(B, J = t)}{P(J = t)} & \\hspace{50pt} \\textrm{[product rule]} \\\\\n",
    "& = \\alpha * \\sum_{E \\in \\{t, f\\}}\\sum_{A \\in \\{t, f\\}}\\sum_{M \\in \\{t, f\\}}P(B, E, A, J = t, M) & \\hspace{50pt} \\textrm{[sum rule]} \\\\\n",
    "& = \\alpha * \\sum_{E \\in \\{t, f\\}}\\sum_{A \\in \\{t, f\\}}\\sum_{M \\in \\{t, f\\}}P(B) * P(E) * P(A\\ |\\ B, E) * P(J = t\\ |\\ A) * P(M\\ |\\ A) & \\hspace{50pt} \\textrm{[Factorisation]}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\alpha = \\frac{1}{P(J = t)}$ is the **normalisation factor**, and is not needed to calculate (we can simply normalise the conditional probabilities for all possible query variable values so that they add up to 1).\n",
    "\n",
    "We can see that except $\\alpha$, all the probabilities $P(B)$, $P(E)$, $P(A\\ |\\ B, E)$, $P(J = t\\ |\\ A)$, $P(M\\ |\\ A)$ can be directly read from the probability tables of the Bayesian network. Therefore, we have successfully found a way to calculate the probability. \n",
    "\n",
    "<!-- In general, given the query nodes $\\{X_1, \\dots, X_n\\}$, evidence nodes $\\{Y_1 = y_1, \\dots, Y_m = y_m\\}$ and hidden nodes $\\{H_1, \\dots, H_k\\}$, the inference can be done as follows.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& P(X_1, \\dots, X_n\\ |\\ Y_1 = y_1, \\dots, Y_m = y_m) \\\\ \n",
    "& = \\frac{P(X_1, \\dots, X_n, Y_1 = y_1, \\dots, Y_m = y_m)}{P(Y_1 = y_1, \\dots, Y_m = y_m)} & \\hspace{50pt} \\textrm{[product rule]} \\\\\n",
    "& = \\alpha * \\sum_{[h_1, \\dots, h_k] \\in \\\\ \\Omega(H_1, \\dots, H_k)} P(X_1, \\dots, X_n, Y_1 = y_1, \\dots, Y_m = y_m, H_1 = h_1, \\dots, H_k = h_k) & \\hspace{50pt} \\textrm{[sum rule]} \\\\\n",
    "& = \\alpha * \\sum_{[h_1, \\dots, h_k] \\in \\\\ \\Omega(H_1, \\dots, H_k)} \\prod_{i=1}^{n} P(X_i\\ |\\ parents(X_i)) * \\prod_{i=1}^{m} P(y_i\\ |\\ parents(Y_i)) * \\prod_{i=1}^{k} P(h_i\\ |\\ parents(H_i)) & \\hspace{50pt} \\textrm{[Factorisation]}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\alpha = \\frac{1}{P(Y_1 = y_1, \\dots, Y_m = y_m)}$ is the **normalisation factor**, and is not needed to calculate (we can simply normalise the conditional probabilities for all possible query variable values so that they add up to 1). -->\n",
    "\n",
    "Finally, we can see that except $\\alpha$, all the probabilities can be directly read from the probability tables in the Bayesian network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computational Complexity\n",
    "\n",
    "If we directly calculate $P(B\\ |\\ J = t)$, how many operations are needed? When we look at the last line (ignoring $\\alpha$), \n",
    "\n",
    "$$\n",
    "\\sum_{E \\in \\{t, f\\}}\\sum_{A \\in \\{t, f\\}}\\sum_{M \\in \\{t, f\\}}P(B) * P(E) * P(A\\ |\\ B, E) * P(J = t\\ |\\ A) * P(M\\ |\\ A)\n",
    "$$\n",
    "\n",
    "For each $B \\in \\{t, f\\}$, we have $2 \\times 2 \\times 2 = 8$ terms to be added. In total, there are $2 \\times 7 = 14$ additions.\n",
    "\n",
    "For each $B \\in \\{t, f\\}$, $E \\in \\{t, f\\}$, $A \\in \\{t, f\\}$ and $M \\in \\{t, f\\}$, there are 5 probabilities to be multiplied, needing 4 multiplications. In total, there are $2^4 \\times 4 = 64$ multiplications.\n",
    "\n",
    "\n",
    "<!-- In general, to calculate\n",
    "\n",
    "$$\n",
    "\\sum_{[h_1, \\dots, h_k] \\in \\\\ \\Omega(H_1, \\dots, H_k)} \\prod_{i=1}^{n} P(X_i\\ |\\ parents(X_i)) * \\prod_{i=1}^{m} P(y_i\\ |\\ parents(Y_i)) * \\prod_{i=1}^{k} P(h_i\\ |\\ parents(H_i))\n",
    "$$\n",
    "\n",
    "- For each possible query values, there are $|\\Omega(H_1)| * \\dots * |\\Omega(H_k)|$ terms to be added, which is the number of possible value combinations of the hidden variables. There are $|\\Omega(H_1)| * \\dots * |\\Omega(H_k)| - 1$ number of additions.\n",
    "- There are $|\\Omega(X_1)| * \\dots * |\\Omega(X_n)|$ possible query values. Therefore, **there are $|\\Omega(X_1)| * \\dots * |\\Omega(X_n)| * (|\\Omega(H_1)| * \\dots * |\\Omega(H_k)| - 1)$ additions in total.**\n",
    "- Each term has $n+m+k$ probabilities to be multiplied, needing $n+m+k-1$ multiplications.\n",
    "- There are $|\\Omega(X_1)| * \\dots * |\\Omega(X_n)| * |\\Omega(H_1)| * \\dots * |\\Omega(H_k)|$ terms in total. Therefore, **there are $|\\Omega(X_1)| * \\dots * |\\Omega(X_n)| * |\\Omega(H_1)| * \\dots * |\\Omega(H_k)| *(n+m+k-1)$ multiplications in total.** -->\n",
    "\n",
    "In large and complex Bayesian networks, the complexity can be intractable. For example, if all the variables are binary, i.e. $|\\Omega(X)| = 2$, if we have 1 query node, 3 evidence nodes and 10 hidden nodes, then the total number of multiplications will be\n",
    "\n",
    "$$\n",
    "2^{(1+10)} \\times (1+3+10-1) = 26624.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speed Up by Variable Elimination\n",
    "\n",
    "The **Variable Elimination** algorithm is a very important exact inference algorithm that speeds up the above calculation process. The key idea is to **eliminate hidden variables as early as possible**. \n",
    "\n",
    "> **DEFINITION**: A **factor** of some random variables is a table of some probabilities of all the possible values of the random variables. Note that the probability can be any probability involving the random variables.\n",
    "\n",
    "To calculate\n",
    "\n",
    "$$\n",
    "\\sum_{E \\in \\{t, f\\}}\\sum_{A \\in \\{t, f\\}}\\sum_{M \\in \\{t, f\\}}P(B) * P(E) * P(A\\ |\\ B, E) * P(J = t\\ |\\ A) * P(M\\ |\\ A)\n",
    "$$\n",
    "\n",
    "We can define five initial **factors**, each for a probability in this equation.\n",
    "\n",
    "$f_1(B) = P(B)$:\n",
    "\n",
    "| B | P(B) |\n",
    "| - | --------------- |\n",
    "| t |    0.001        |\n",
    "| f |    0.999        |\n",
    "\n",
    "$f_2(E) = P(E)$:\n",
    "\n",
    "| E | P(E) |\n",
    "| - | --------------- |\n",
    "| t |    0.002        |\n",
    "| f |    0.998        |  \n",
    "\n",
    "$f3(A, B, E) = P(A\\ |\\ B, E)$:\n",
    "\n",
    "| A | B | E | P(A &#124; B, E) |\n",
    "| - | - | - | --------------- |\n",
    "| t | t | t |   0.95        |\n",
    "| f | t | t |   0.05        |\n",
    "| t | t | f |   0.94        |\n",
    "| f | t | f |   0.06        |\n",
    "| t | f | t |   0.29        |\n",
    "| f | f | t |   0.71        |\n",
    "| t | f | f |   0.001        |\n",
    "| f | f | f |   0.999        |    \n",
    "\n",
    "$f_4(A) = P(J=t\\ |\\ A)$:\n",
    "\n",
    "| A | P(J=t &#124; A) |\n",
    "| - | --------------- |\n",
    "| t |    0.9        |\n",
    "| f |    0.05        | \n",
    "\n",
    "$f_5(M, A) = P(M\\ |\\ A)$:\n",
    "\n",
    "| M | A | P(M &#124; A) |\n",
    "| - | - | --------------- |\n",
    "| t | t |   0.7        |\n",
    "| f | t |   0.3        |  \n",
    "| t | f |   0.01        |\n",
    "| f | f |   0.99        |  \n",
    "\n",
    "> **DEFINITION**: The **join** operation between two factors $f_1$ and $f_2$, denoted as $f_1 \\otimes f_2$, is a table of the *union* of the variables in $f_1$ and $f_2$, where each row is the multiplication of the corresponding row of $f_1$ and $f_2$.\n",
    "\n",
    "In the above example, $f_1(B) \\otimes f_2(E) = P(B) * P(E)$ is shown as follows. It converts two 2-row tables into a 4-row table, leading to 4 multiplications.\n",
    "\n",
    "| B | E | P(B) * P(E) |\n",
    "| - | - | --------------- |\n",
    "| t | t |   0.001 * 0.002 = 0.000002        |\n",
    "| f | t |   0.999 * 0.002 = 0.001998      |  \n",
    "| t | f |   0.001 * 0.998 = 0.000998        |\n",
    "| f | f |   0.999 * 0.998 = 0.997002       | \n",
    "\n",
    "On the other hand, $f_4(A) \\otimes f_5(M, A) = P(J = t\\ |\\ A) * P(M\\ |\\ A)$ is shown as follows.\n",
    "\n",
    "| M | A | P(J = t &#124; A) * P(M &#124; A) |\n",
    "| - | - | --------------- |\n",
    "| t | t |   0.9 * 0.7 = 0.63        |\n",
    "| f | t |   0.9 * 0.3 = 0.27        |  \n",
    "| t | f |   0.05 * 0.01 = 0.0005       |\n",
    "| f | f |   0.05 * 0.99 = 0.0495       | \n",
    "\n",
    "Due to the overlap between the variables of the two joined factors, the resultant table is still 4 rows, the same as the original $f_5$. In general, **the complexity of the join operator depends on the size of the joint factors and their overlapping variables**.\n",
    "\n",
    "> **DEFINITION**: The **elimination/sum-out** operation of a factor $f(X, Y)$ on $X$ is a table of $Y$, where each row is the sum of the all the rows in $f(X, Y)$ with the corresponding $Y=y$ value.\n",
    "\n",
    "For example, if we **eliminate/sum-out** $M$ in $f_4(A) \\otimes f_5(M, A)$, then we can obtain the following factor.\n",
    "\n",
    "| A | P(J = t &#124; A) * P(M = t &#124; A) + P(J = t &#124; A) * P(M = f &#124; A) |\n",
    "| - | --------------- |\n",
    "| t |    0.63 + 0.27 = 0.9        |\n",
    "| f |    0.0005 + 0.0495 = 0.05        | \n",
    "\n",
    "Elimination/Sum-out can reduce the size of the factor.\n",
    "\n",
    "Then, we can write the calculation of the conditional probabilities as the factor operations.\n",
    "\n",
    "$$\n",
    "\\sum_{E \\in \\{t, f\\}}\\sum_{A \\in \\{t, f\\}}\\sum_{M \\in \\{t, f\\}}P(B) * P(E) * P(A\\ |\\ B, E) * P(J = t\\ |\\ A) * P(M\\ |\\ A)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathtt{Elim}_{E}\\mathtt{Elim}_{A}\\mathtt{Elim}_{M}f_1(B) \\otimes f_2(E) \\otimes f_3(A, B, E) \\otimes f_4(A) \\otimes f_5(M, A)\n",
    "$$\n",
    "\n",
    "Note that the order of the join and elimination operations can be swapped freely. To save computational cost, we should eliminate variables as early as possible to reduce the size of the tables for later join operations. The **variable elimination** algorithm is proposed to this end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "def variable_elimination(query_nodes, evidence_nodes, observations, hidden_nodes):\n",
    "    Set all_nodes = [query_nodes, evidence_nodes, hidden_nodes]\n",
    "    # Initialise the factors\n",
    "    factors = []\n",
    "    for node in all_nodes:\n",
    "        Initialise factor = P(node | parents(node)) with the observations\n",
    "        Add factor into factors\n",
    "        \n",
    "    Sort hidden_nodes in some way\n",
    "    \n",
    "    # At each iteration, eliminate one hidden node\n",
    "    for node in sorted_hidden_nodes:\n",
    "        Join all the factors containing node\n",
    "        Eliminate node from the joined factor\n",
    "    \n",
    "    Join all the factors containing query_nodes\n",
    "    Normalise the probabilities in the final factor\n",
    "    return the final factor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the process of the `variable_elimination` algorithm to calculate $P(B\\ |\\ J)$ through the following equation as follows. Let the order of the hidden variables be $M \\rightarrow A \\rightarrow E$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "& \\mathtt{Elim}_{E}\\mathtt{Elim}_{A}\\mathtt{Elim}_{M}f_1(B) \\otimes f_2(E) \\otimes f_3(A, B, E) \\otimes f_4(A) \\otimes f_5(M, A) \\\\\n",
    "& = \\underbrace{f_1(B) \\otimes \\underbrace{\\mathtt{Elim}_{E} f_2(E) \\otimes \\underbrace{\\mathtt{Elim}_{A} f_3(A, B, E) \\otimes f_4(A) \\otimes \\underbrace{\\mathtt{Elim}_{M} f_5(M, A)}_{f_6(A)}}_{f_8(B, E)}}_{f_{10}(B)}}_{f_{11}(B)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- **Iteration 1**: Eliminate $M$ from $f_5(M, A)$, which is the only factor containing $M$, to get $f_6(A)$. It costs <span style=\"color: blue;\">**2 additions**</span>.\n",
    "\n",
    "| A | f6(A) |\n",
    "| - | --------------- |\n",
    "| t |    0.7 + 0.3 = 1.0        |\n",
    "| f |    0.01 + 0.99 = 1.0        |\n",
    "\n",
    "- **Iteration 2**: \n",
    "    1. Join all the factors containing $A$, $f_3(A, B, E)$, $f_4(A)$ and $f_6(A)$, to obtain $f_7(A, B, E)$. It costs <span style=\"color: red;\">**16 multiplications**</span>.\n",
    "    \n",
    "    | A | B | E | f7(A, B, E) |\n",
    "    | - | - | - | --------------- |\n",
    "    | t | t | t |   0.95 * 0.9 * 1.0 = 0.855       |\n",
    "    | f | t | t |   0.05 * 0.05 * 1.0 = 0.0025       |\n",
    "    | t | t | f |   0.94 * 0.9 * 1.0 = 0.846      |\n",
    "    | f | t | f |   0.06 * 0.05 * 1.0 = 0.003      |\n",
    "    | t | f | t |   0.29 * 0.9 * 1.0 = 0.261      |\n",
    "    | f | f | t |   0.71 * 0.05 * 1.0 = 0.0355      |\n",
    "    | t | f | f |   0.001 * 0.9 * 1.0 = 0.0009      |\n",
    "    | f | f | f |   0.999 * 0.05 * 1.0 = 0.04995      | \n",
    "    \n",
    "    2. Eliminate $A$ from $f_7(A, B, E)$ to obtain $f_8(B, E)$. It costs <span style=\"color: blue;\">**4 additions**</span>.\n",
    "    \n",
    "    | B | E | f8(B, E) |\n",
    "    | - | - | --------------- |\n",
    "    | t | t |   0.855 + 0.0025 = 0.8575          |\n",
    "    | f | t |   0.261 + 0.0355 = 0.2965       |  \n",
    "    | t | f |   0.846 + 0.003 = 0.849       |\n",
    "    | f | f |   0.0009 + 0.04995 = 0.05085    | \n",
    "    \n",
    "- **Iteration 3**:\n",
    "    1. Join all the factors containing $E$, $f_2(E)$ and $f_8(B, E)$, to obtain $f_9(B, E)$. It costs <span style=\"color: red;\">**4 multiplications**</span>.\n",
    "    \n",
    "    | B | E | f9(B, E) |\n",
    "    | - | - | --------------- |\n",
    "    | t | t |   0.002 * 0.8575 = 0.001715        |\n",
    "    | f | t |   0.002 * 0.2965 = 0.000593      |  \n",
    "    | t | f |   0.998 * 0.849 = 0.847302        |\n",
    "    | f | f |   0.998 * 0.05085 = 0.0507483       | \n",
    "    \n",
    "    2. Eliminate $E$ from $f_9(B, E)$ to obtain $f_{10}(B)$. It costs <span style=\"color: blue;\">**2 additions**</span>.\n",
    "    \n",
    "    | B | f10(B) |\n",
    "    | - | --------------- |\n",
    "    | t |    0.001715 + 0.847302 = 0.849017       |\n",
    "    | f |    0.000593 + 0.0507483 = 0.0513413        |\n",
    "\n",
    "- **Iteration 4**: Join all the factors containing $B$, $f_1(B)$ and $f_{10}(B)$, to obtain $f_{11}(B)$. It costs <span style=\"color: red;\">**2 multiplications**</span>.\n",
    "\n",
    "| B | f11(B) |\n",
    "| - | --------------- |\n",
    "| t |    0.001 * 0.849017 = 0.000849017       |\n",
    "| f |    0.999 * 0.0513413 = 0.0512899587        |\n",
    "\n",
    "In total, the variable elimination costs <span style=\"color: blue;\">**8 additions**</span> and <span style=\"color: red;\">**22 multiplications**</span>, which is much smaller than the original 14 additions and 64 multiplications.\n",
    "\n",
    "Finally, we normalise the probabilities in $f_{11}(B)$ to obtain the final factor:\n",
    "\n",
    "| B | norm f11(B) |\n",
    "| - | --------------- |\n",
    "| t |    0.000849017 / (0.000849017 + 0.0512899587) = 0.01628372994      |\n",
    "| f |    0.0512899587 / (0.000849017 + 0.0512899587) = 0.98371627005        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1645148223571,
     "user": {
      "displayName": "Yi Mei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjbsloGGj8mKvkgwfMTyhu9iqFZUz599lVh7y-zA=s64",
      "userId": "14923329265121969261"
     },
     "user_tz": -780
    },
    "id": "sFC-F5R6eapJ",
    "outputId": "10a10224-d205-4509-fb2a-90a70427c893"
   },
   "source": [
    "Let's verify the results by the `VariableElimination` function in the `pgmpy` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268,
     "referenced_widgets": [
      "4eeaa192b99849988659547ed6f8a17b",
      "e0ba45aac28749c7a189293ca73dc51b",
      "ebbedb522c874b79a1095af4963bd976",
      "3c120f9e3aeb46119d12f74ac1035992",
      "5f75346373df4a13a6fb38f557b8d259",
      "8b33c262861e433286b8a3601aaa8391",
      "50331471295a4a40934016b913fb515b",
      "44df7ae731d848d894bc5c1c6d1c1b19",
      "6557561de25f435190bc75158f6b5064",
      "2e0959ce50f744d9ac8a801878f29c99",
      "7a797eefb0fd4a1787240a9fb24cd338",
      "865d602624a641b984c01a84e2a6bd49",
      "87939cd8df4f4a45b553df2b37f4524b",
      "53ce67001ef5424696addd3eaf8de144",
      "4ed92c6ebfad491dbb7838cf9040f789",
      "fd119f513d5d4433a211898cec4e374b",
      "30dfd17e6f1f4bbd9cefdbbb92cb4958",
      "a39141612b074880aa5637c8cafeaefa",
      "d27706f35c334b51ad555598e9a261ef",
      "211ec25b1db34e999c1bc53329d42f44",
      "0e1a5c69cfed4342892752d5b4131c2d",
      "7a1a9a0fad754286bffa70151701f414"
     ]
    },
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1645148294086,
     "user": {
      "displayName": "Yi Mei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjbsloGGj8mKvkgwfMTyhu9iqFZUz599lVh7y-zA=s64",
      "userId": "14923329265121969261"
     },
     "user_tz": -780
    },
    "id": "bziY1or2TcXF",
    "outputId": "26d939c5-81df-4b2a-fb54-a7ac8d585eaf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce89b8848f084842a7ce526f26e50271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e0ea946bc641698aecbb2287cdb6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "| Burglary    |   phi(Burglary) |\n",
      "+=============+=================+\n",
      "| Burglary(0) |          0.9837 |\n",
      "+-------------+-----------------+\n",
      "| Burglary(1) |          0.0163 |\n",
      "+-------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "alarm_infer = VariableElimination(alarm_model)\n",
    "\n",
    "q = alarm_infer.query(variables=[\"Burglary\"], evidence={\"JohnCall\": 1})\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `pgmpy` library gives the same results, which verifies the correctness of our calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "*[Back to Table of Content](#toc)*\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original Juypter Notebook can be downloaded [here](https://homepages.ecs.vuw.ac.nz/~yimei/tutorials/bayesian-network.ipynb).\n",
    "\n",
    "More tutorials can be found [here](https://meiyi1986.github.io/tutorials/).\n",
    "\n",
    "[Yi Mei's homepage](https://meiyi1986.github.io/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUhVpwLgftmeLtOZUU/BvG",
   "name": "murderer-bn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e1a5c69cfed4342892752d5b4131c2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "211ec25b1db34e999c1bc53329d42f44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e0959ce50f744d9ac8a801878f29c99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30dfd17e6f1f4bbd9cefdbbb92cb4958": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c120f9e3aeb46119d12f74ac1035992": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6557561de25f435190bc75158f6b5064",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_44df7ae731d848d894bc5c1c6d1c1b19",
      "value": 2
     }
    },
    "44df7ae731d848d894bc5c1c6d1c1b19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4ed92c6ebfad491dbb7838cf9040f789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_211ec25b1db34e999c1bc53329d42f44",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d27706f35c334b51ad555598e9a261ef",
      "value": 2
     }
    },
    "4eeaa192b99849988659547ed6f8a17b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebbedb522c874b79a1095af4963bd976",
       "IPY_MODEL_3c120f9e3aeb46119d12f74ac1035992",
       "IPY_MODEL_5f75346373df4a13a6fb38f557b8d259"
      ],
      "layout": "IPY_MODEL_e0ba45aac28749c7a189293ca73dc51b"
     }
    },
    "50331471295a4a40934016b913fb515b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53ce67001ef5424696addd3eaf8de144": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a39141612b074880aa5637c8cafeaefa",
      "placeholder": "​",
      "style": "IPY_MODEL_30dfd17e6f1f4bbd9cefdbbb92cb4958",
      "value": "Eliminating: Weapon: 100%"
     }
    },
    "5f75346373df4a13a6fb38f557b8d259": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a797eefb0fd4a1787240a9fb24cd338",
      "placeholder": "​",
      "style": "IPY_MODEL_2e0959ce50f744d9ac8a801878f29c99",
      "value": " 2/2 [27:43&lt;00:00, 831.94s/it]"
     }
    },
    "6557561de25f435190bc75158f6b5064": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a1a9a0fad754286bffa70151701f414": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a797eefb0fd4a1787240a9fb24cd338": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "865d602624a641b984c01a84e2a6bd49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53ce67001ef5424696addd3eaf8de144",
       "IPY_MODEL_4ed92c6ebfad491dbb7838cf9040f789",
       "IPY_MODEL_fd119f513d5d4433a211898cec4e374b"
      ],
      "layout": "IPY_MODEL_87939cd8df4f4a45b553df2b37f4524b"
     }
    },
    "87939cd8df4f4a45b553df2b37f4524b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b33c262861e433286b8a3601aaa8391": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a39141612b074880aa5637c8cafeaefa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d27706f35c334b51ad555598e9a261ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0ba45aac28749c7a189293ca73dc51b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebbedb522c874b79a1095af4963bd976": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50331471295a4a40934016b913fb515b",
      "placeholder": "​",
      "style": "IPY_MODEL_8b33c262861e433286b8a3601aaa8391",
      "value": "Finding Elimination Order: : 100%"
     }
    },
    "fd119f513d5d4433a211898cec4e374b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a1a9a0fad754286bffa70151701f414",
      "placeholder": "​",
      "style": "IPY_MODEL_0e1a5c69cfed4342892752d5b4131c2d",
      "value": " 2/2 [00:00&lt;00:00, 37.07it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
